{"/":{"title":"Glossary ğŸ§ ","content":"\n## A Single Place for All Data Knowledge\nWe have a collection of many terms that are constantly evolving and being added to them. To see all terms you can either:\n* click on *[All Terms of the Glossary](term)* \n* or seeing them *[by Tags](tags)*\n\nYou can simply [Search](https://glossary.airbyte.com/#navigation) for terms and content.\n\n### Contribute\nEverything on this Glossary is open-sourced on GitHub and you can contribute if you like.\n\u003e [!info] How to Contribute?\n\u003e \n\u003e 1.  â­ Star ourÂ [GitHub](https://github.com/airbyteglossary/airbyteglossary.github.io)Â repo\n\u003e 2.  ğŸ—£ï¸Â  [Share the Glossary](https://twitter.com/intent/tweet?text=Have%20you%20seen%20the%20latest%20on%20the%20%22Airbyte%20Glossary%20%F0%9F%A7%A0?%20glossary.airbyte.com)\n\u003e 3.  âœï¸Â Missing a Term or want to fix a typo? [contribute to glossary](term/contribute%20to%20glossary.md) \n\u003e 4. ğŸ‘€ Want to discuss or need help, talk to us on [Slack](https://slack.airbyte.com)\n\n### Navigation\nYou can simply hit `ctrl/cmd+k` and **search** the whole Data Brain. Or you can click on the links and navigation through our content. \n\n### Interactive Graph\nUse the `Interactive Graph` on the bottom. It will appear every term. You can zoom and click on different nodes to navigate through the content.\n\n## About this Glossary\nThe Airbyte Glossary is built on top of the [Digital Garden](https://jzhao.xyz/posts/networked-thought/) analogy. Instead of aligning all glossary terms in a single level, the digital garden approach lets you go inwards. You can learn about each term and go deeper into each of its connections. The Glossary will show you each link that is related to the above interactive graph to it and all backlinks. \n\nThese will allow you to see connections in a visual way, that you would not otherwise.\n\nThis Glossary is forked from [Quartz](https://github.com/jackyzha0/quartz) and we thank Jacky for open-sourcing this gem.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/ACID-Transactions":{"title":"What are ACID Transactions","content":"AnÂ ACID transactionÂ secures that either all changes are successfully committed or rollbacked. It makes sure you never end in an inconsistent state. There is different concurrency control that, for example, guarantees consistency between reads and writes. EachÂ [Data Lake Table Format](term/data%20lake%20table%20format.md)Â has other implementations and features here.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Airbyte-Streams":{"title":"What are Airbyte Streams","content":"In order to understandÂ **AirbyteStreams**, letâ€™s first talk about theÂ **AirbyteCatalog**. AnÂ **AirbyteCatalog**Â describes the structure of data in a data source. It has a single field called streams that contains a list ofÂ **AirbyteStreams**. EachÂ **AirbyteStream**Â contains aÂ _name_Â andÂ _json_schema_Â field. TheÂ _json_schema_Â field describes the structure of a stream. This data model is intentionally flexible.\n\nIf we are using a data source that is a traditional relational database, each table in that database would map to anÂ **AirbyteStream**. Each column in the table would be a key in theÂ _properties_Â field of the _json_schema_Â field.\n\nIf we are using a data source that wraps an API with multiple different resources (e.g.Â _api/customers_Â andÂ _api/products_) each route would correspond to a stream.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Apache-Arrow":{"title":"What is Apache Arrow","content":"Apache Arrow is a development platform for in-memory analytics. It contains a set of technologies that enable big data systems to process and move data fast.\n\nRead more on [Data Lake File Format](term/data%20lake%20file%20format.md).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Apache-Avro":{"title":"What is Apache Avro","content":"Avro is an open-source data serialization system that helps with data exchange between systems, programming languages, and processing frameworks. Avro helps define a binary format for your data, as well as map it to the programming language of your choice.\n\nAvro has a JSON-like data model, but can be represented as either JSON or in a compact binary form. It comes with aÂ **very sophisticated schema description language**Â that describes data. Avro is anotherÂ [Data Lake File Format](term/data%20lake%20file%20format.md).\n\nRead more about how to build a Data Lake on top of it on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Apache-Hadoop":{"title":"What is Apache Hadoop","content":"Apache Hadoop is a collection of open-source software utilities that facilitates using a network of many computers to solve problems involving massive amounts of data and computation. It provides a software framework for distributed storage and processing of big data using the [MapReduce](term/mapreduce.md) programming model.\n","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Apache-Hive":{"title":"What is Apache Hive","content":"Apache Hive is aÂ [Data Warehouse](term/data%20warehouse.md)Â software project built on top ofÂ [Apache Hadoop](term/apache%20hadoop.md)Â for providing data queries and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop. Traditional SQL queries must be implemented in theÂ [MapReduce](term/mapreduce.md)Â Java API to execute SQL applications and queries over distributed data. Hive provides the necessary SQL abstraction to integrate SQL-like queries ([HiveQL](https://en.wikipedia.org/wiki/Apache_Hive#HiveQL)) into the underlying Java without the need to implement queries in the low-level Java API.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Apache-Hudi":{"title":"What is Apache Hudi","content":"Apache Hudi is aÂ [Data Lake Table Format](term/data%20lake%20table%20format.md)Â and was originally developed at Uber in 2016 (code-named and pronounced \"Hoodie\"), open-sourced end of 2016 ([first commit](https://github.com/apache/hudi/commit/0512da094bad2f3bcd2ddddc29e8abfec175dcfe)Â in 2016-12-16), and submitted to the Apache Incubator in January 2019. More about the back story onÂ [The Apache Software Foundation Announces ApacheÂ® Hudiâ„¢ as a Top-Level Project](https://www.globenewswire.com/news-release/2020/06/04/2043732/0/en/The-Apache-Software-Foundation-Announces-Apache-Hudi-as-a-Top-Level-Project.html).\n\nRead more about how to build a Data Lake on top of it on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Apache-Iceberg":{"title":"What is Apache Iceberg","content":"Apache Iceberg is aÂ [Data Lake Table Format](term/data%20lake%20table%20format.md)Â and wasÂ [initially developed](https://github.com/Netflix/iceberg)Â at Netflix to solve long-standing issues using huge, petabyte-scale tables. It was open-sourced in 2018 as an Apache Incubator project and graduated from the incubator on the 19th of May 2020. TheirÂ [first public commit](https://github.com/apache/iceberg/commit/a5eb3f6ba171ecfc517a4f09ae9654e7d8ae0291)Â was 2017-12-19â€”more insights about the story onÂ [A Short Introduction to Apache Iceberg](https://medium.com/expedia-group-tech/a-short-introduction-to-apache-iceberg-d34f628b6799).\n\nRead more about how to build a Data Lake on top of it on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Apache-Parquet":{"title":"What is Apache Parquet","content":"Apache Parquet is a free and open-source column-orientedÂ [Data Lake File Format](term/data%20lake%20file%20format.md)Â in the Apache Hadoop ecosystem. It is similar to RCFile andÂ [ORC](term/orc.md), the other columnar-storage file formats in Hadoop, and is compatible with most of the data processing frameworks around Hadoop.\n\nRead more about how to build a Data Lake on top of it on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Contribute-to-Glossary":{"title":"How to Contribute to the Glossary","content":"You can either click on `Edit Source` on each page and directly edit on GitHub or you can create a [New Issue](https://github.com/airbyteglossary/airbyteglossary.github.io/issues).\n\nThe nice thing is you can also run it locally and edit with [Obsidian](https://obsidian.md/) (if the GitHub direct edit is not enough or you want to change the design). \n\nFor that, you can check a step-by-step manual [here](https://quartz.jzhao.xyz/notes/setup/) and the specific setting you need to have in Obsidian [here](https://quartz.jzhao.xyz/notes/obsidian/). Note that I pushed the Obsidian settings already to the GitHub repo, you only need to download Obsidian and open the Vault at `content/`(there is a hidden folder `content/.obsidian` that contains these already).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Asset":{"title":"What is a Data Asset","content":"A data asset is typically a database table, a machine learning model, or a report. A persistent object that captures some understanding of the world. It's more a technical term whereÂ [Data Product](term/data%20product.md)Â is more used in general or inÂ [Data Mesh](term/data%20mesh.md).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Catalog":{"title":"What is a Data Catalog","content":"A Data CatalogÂ is a centralized store where all your metadata data about your data is made searchable.\n\n**Think about a Google Search for your internal Metadata**. This is vital, as withÂ [Data Lake](term/data%20lake.md)Â and other data stores, and you want the ability to search for your data. Data is growing exponentially, with 90% of the worldâ€™s data being generated alone in the last two years. It's hard to keep this amount over time. A data catalog solves the problem of the fast-growing handling of data internally.\n\nAn interesting read about the beginning of the Data Catalog is explained in the 2017 published paper about aÂ [Data Context Service](http://cidrdb.org/cidr2017/papers/p111-hellerstein-cidr17.pdf). See as well theÂ [Awesome Data Discovery and Observability](https://github.com/opendatadiscovery/awesome-data-catalogs)Â list on GitHub for an extensive list of existing tools.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Governance":{"title":"What is Data Governance","content":"[**Data governance**](https://www.talend.com/resources/what-is-data-governance/)Â **is a collection of processes, roles, policies, standards, and metrics that ensure the effective and efficient use of information in enabling an organization to achieve its goals.**Â It establishes the processes and responsibilities that ensure the quality and security of the data used across a business or organization. Data governance defines who can take what action, upon what data, in what situations, and using what methods.\n\nRead more on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Lake":{"title":"What is a Data Lake","content":"A Data Lake is a storage system with vast amounts of unstructured and structured data, stored as-is, without a specific purpose in mind, that can be built on multiple technologies such as Hadoop, NoSQL, Amazon Simple Storage Service, a relational database, or various combinations and different formats (e.g. Excel, CSV, Text, Logs, etc.).\n\nAccording toÂ [Hortonworks Data Lake Whitepaper](http://hortonworks.com/wp-content/uploads/2014/05/TeradataHortonworks_Datalake_White-Paper_20140410.pdf), the data lake arose because new types of data needed to be captured and exploited by the enterprise. As this data became increasingly available, early adopters discovered that they could extract insight through new applications built to serve the business. The data lake supports the following capabilities:\n-   To capture and store raw data at scale for a low cost\n-   To store many types of data in the same repository\n-   To perform transformations on the data where the purpose may not be defined\n-   To perform new types of data processing\n-   To perform single-subject analytics based on particular use cases\n\nThe initial concept was created by Databricks in theÂ [CIDR Paper](http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf)Â in 2021. Read more on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Lake-File-Format":{"title":"What is a Data Lake File Format","content":"Data lake file formats are the new CSVs on the cloud. They are more column-oriented and compress large files with added features. The main players here are [Apache Parquet](term/apache%20parquet.md), [Apache avro](term/apache%20avro.md), and [Apache arrow](term/apache%20arrow.md). Itâ€™s the physical store with the actual files distributed around different buckets on yourÂ [Object Store](term/storage%20layer.md).\n\nYou can build more features with [Data Lake Table Format](term/data%20lake%20table%20format.md) on top. Read more on our [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Lake-Table-Format":{"title":"What is a Data Lake Table Format","content":"Data lake table formats are very attractive as they are databases onÂ [Data Lake](term/data%20lake.md). Same as a table, oneÂ **data lake table format bundles distributed files into one table that is otherwise hard to manage**. You can think of it as an abstraction layer between your physical data files and how they are structured to form a table.\n\nIt is built on top o the [Storage Layer](term/storage%20layer.md) and [Data Lake File Format](term/data%20lake%20file%20format.md). Read more on our [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).\n","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Lake-Transaction-Log":{"title":"What is a Data Lake Transaction Log","content":"TheÂ **data lake transaction log**Â is the ordered record of every transaction since its inception. A transaction log is a common component used through many of its above-mentioned features, includingÂ [ACID Transactions](term/acid%20transactions.md), scalable metadata handling, andÂ [Time Travel](term/time%20travel.md). For example,Â [Delta Lake](term/delta%20lake.md)Â creates a singleÂ [folder called `_delta_log`](https://airbyte.com/tutorials/load-data-into-delta-lake-on-databricks-lakehouse#step-5).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Lakehouse":{"title":"What is a Data Lakehouse","content":"\nA Data Lakehouse open data management architecture that combines the flexibility, cost-efficiency, and scale ofÂ [Data Lake](term/data%20lake.md)Â with the data management and ACID transactions ofÂ [Data Warehouse](term/data%20warehouse.md)Â with Data Lake Table FormatsÂ (DeltaÂ Lake, Apache Iceberg \u0026 Hudi) that enable Business IntelligenceÂ (BI) and Machine LearningÂ (ML) on all data.\n\nThe initial concept was created by Databricks in theÂ [CIDR Paper](http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf)Â in 2021. Read more on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Lineage":{"title":"What is Data Lineage","content":"Data lineage uncovers the life cycle of data. It aims to show the complete data flow from start to finish. Data lineage is the process of understanding, recording, and visualizing data as it flows from data sources to consumption. This includes all data transformations (what changed and why).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Mesh":{"title":"What is Data Mesh","content":"TheÂ [Data Mesh Paper](https://martinfowler.com/articles/data-monolith-to-mesh.html)Â tries to eliminate silos between data teams, ensuring that the experience and knowledge about data are shared among all data consumers in the company. Data Mesh seesÂ [Data As a product](term/data%20product.md). Data meshes are also about connecting platforms that those teams are using so data can be easily moved around for the organization's benefit. Companies will try to find better ways of unifying and connecting the tools so that data professionals donâ€™t have to switch and work in a silo.\n\nData meshes try to eliminate the tensions between decentralizing and centralizing data resources, with some common infrastructure but otherwise mostly decentralized. It empowers data teams and gives ownership to domain experts.\n\nMore valuable resources such as aÂ [short version](https://cnr.sh/essays/what-the-heck-data-mesh), aÂ [visually appealing one](https://www.datamesh-architecture.com/)), orÂ [applied in practice](https://youtu.be/eiUhV56uVUc).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Orchestrator":{"title":"What is a Data Orchestrator","content":"A Data OrchestratorÂ models dependencies between different tasks inÂ [complex heterogeneous cloud environments](https://mattturck.com/data2021/)Â end-to-end. It handles integrations with legacy systems, new cloud-based tools, and your data lakes and data warehouses. ItÂ invokesÂ [computation](https://en.wikipedia.org/wiki/Orchestration_(computing)), such as wrangling your business logic in SQL and Python and applying ML modelsÂ at the right time based on a time-based trigger or by custom-defined logic.\n\nMore Insights inÂ [Data Orchestration Trends: The Shift from Data Pipelines to Data Products](https://airbyte.com/blog/data-orchestration-trends).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Product":{"title":"What is a Data Product","content":"[DJ Patil](https://twitter.com/dpatil), the former Chief Data Scientist of the United States, defined a data product as \"a product that facilitates an end goal through data.\" Also,Â [Data Mesh](term/data%20mesh.md)Â talks about \"data as a product.\" It applies more product thinking, whereas the \"Data Product\" essentially is a dashboard, report, and table in aÂ [Data Warehouse](term/data%20warehouse.md)Â or a Machine Learning model. Sometimes Data Products are also calledÂ [Data Asset](term/data%20asset.md)s.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Swamp":{"title":"What is a Data Swamp","content":"Data swamps start to arise when there is a lack of responsibilities, data ownership, availability, and data governance. Â It's when aÂ [Data Lake](term/data%20lake.md)Â is unmanaged or unable to provide value. Sometimes a Data Swamp can also arise from aÂ [Data Warehouse](term/data%20warehouse.md)Â due to existing hybrid models.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Virtualization":{"title":"What is Data Virtualization","content":"Data Virtualization helps you when you have many source systems from different technologies, but all of them are rather fast in response time, and if you don't run a lot of operational applications. In that way, you don't move and copy data around and pre-aggregate, but you have a semantic layer where you create your business models (like cubes), and only if you query this data virtualization layer does it query the data source. If you use, e.g.Â [Dremio](https://www.dremio.com/), there you useÂ [Apache arrow](term/apache%20arrow.md)Â technology which will cache and optimize a lot in-memory for you that you have as well as stonishing fast response times.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Data-Warehouse":{"title":"What is a Data Warehouse","content":"A Data Warehouse, in short DWH, also known as anÂ Enterprise Data WarehouseÂ (EDW), is the traditional way of collecting data as we doÂ [since 30+ years](https://tdwi.org/articles/2016/02/01/data-warehousing-30.aspx). The DWH serves to be the data integration from many different sources, the single point of truth and the data management, meaning cleaning, historizing, and data joined together. It provides greater executive insight into corporate performance with management Dashboards, Reports, or Ad-Hoc Analyses.\n\nVarious types ofÂ business data are analyzedÂ with Data Warehouses. The need for it often becomes evident when analytic requirements run afoul of the ongoing performance of operational databases. Running a complex query on a database requires the database to enter a temporarily fixed state. It is often untenable for transactional databases. A data warehouse is employed to do the analytical work, leaving the transactional database free to focus on transactions.\n\nThe other characteristic is analyzing data from multiple origins (e.g., your Google Analytics with your CRM data). It is highly transformed and structured due to theÂ ETL (Extract Transform Load) process.\n\nIf you wonder about the difference between a Data Warehouse, Data Lake, and a Lakehouse, read more on our [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/DataOps":{"title":"What is DataOps","content":"Similar to howÂ [DevOps](term/devops.md)Â changed the way software is developed, DataOps is changing the way data products are created. With DataOps, data engineers and data scientists can work together, bringing a level of collaboration and communication, with a common goal of producing valuable insight for the business.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Delta-Lake":{"title":"What is Delta Lake","content":"Delta Lake is an open-sourceÂ [Data Lake Table Format](term/data%20lake%20table%20format.md)Â project created by Databricks and kindly open-sourced with itsÂ [first public GitHub Commit](https://github.com/delta-io/delta/commit/14cb4e0267cc188e0fdd47e5b4f0235baf87874e)Â on 2019-04-22. Recently announcedÂ [Delta Lake 2.0](https://www.databricks.com/blog/2022/06/30/open-sourcing-all-of-delta-lake.html).\n\nRead more about how to build a Data Lake on top of it on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/DevOps":{"title":"What is DevOps","content":"DevOpsÂ is a combination of software developers (dev) and operations (ops). It is defined as a software engineering methodology that aims to integrate the work of software development and software operations teams by facilitating a culture of collaboration and shared responsibility.\n\nIs also related to [DataOps](term/dataops.md)","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Directed-Acyclic-Graph-DAG":{"title":"What is a Directed Acyclic Graph (DAG)","content":"A DAG is a graph where information must travel along with a finite set of nodes connected by vertices. There is no particular start or node and also no way for data to travel through the graph in a loop that circles back to the starting point.\n\nIt's a popular way of building data pipelines in the data engineering community as it clearly defines theÂ [Data Lineage](term/data%20lineage.md). As well, it's made for a functional approach where you have theÂ [idempotency](term/idempotency.md)Â to restart pipelines without side-effects","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Functional-Data-Engineering":{"title":"What is Functional Data Engineering","content":"Functional Data Engineering bringsÂ _clarity_. When functions are \"pure,\" they do not have side effects. They can be written, tested, reasoned about, and debugged in isolation without understanding the external context or history of events surrounding their execution. ItsÂ [Functional Programming](term/functional%20programming.md) applied to the field of data engineering initiated by Maxime Beauchemin withÂ [Functional Data Engineering â€” a modern paradigm for batch data processing](https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a).\n","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Functional-Programming":{"title":"What is Functional Programming?","content":"\nFunctional Programming is a style of building functions that threaten computation as a mathematical function that avoids changing state and mutable data. It is a declarative programming paradigm, which means programming expressive and [declarative](https://airbyte.com/blog/data-orchestration-trends) as opposed to imperative. It's getting more popular with the rise of [Functional Data Engineering](term/functional%20data%20engineering.md).\n","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Idempotency":{"title":"What is Idempotency","content":"Idempotency is the property of a particular operation that can be applied multiple times without changing the resulting outcome by being given the same inputs. It is used inÂ [Functional Programming](term/functional%20programming.md)Â and was the foundation forÂ [Functional Data Engineering](term/functional%20data%20engineering.md).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Incremental-Synchronization":{"title":"What is Incremental Synchronization","content":"Incremental synchronization is a process which efficiently copies data to a destination system by periodically executing queries on a source system for records that have been updated or inserted since the previous sync operation. Only those records that have been recently inserted or updated will be sent to the destination, which is much more efficient than copying an entire data set on each sync operation. Incremental synchronization makes use of a cursor field such as \"updated_at\" (or whatever you wish to call the field) to determine which records should be propagated, and only records with an \"updated_at\" value that is newer than the \"updated_at\" value of the most recent record sent in the previous sync should be replicated.  \n  \nHowever, without special consideration, records that have been deleted in the source system will not be propagated to the destination as they will never appear in the results from such a query. This may be addressed byÂ [Soft Deletes](term/soft%20deletes.md)Â or by making use ofÂ [CDCÂ replication](https://airbyte.com/blog/change-data-capture-definition-methods-and-benefits).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Kubernetes":{"title":"What is Kubernetes","content":"Itâ€™s a platform that allows you to run and orchestrate container workloads.Â [**Kubernetes**](https://stackoverflow.blog/2020/05/29/why-kubernetes-getting-so-popular/)Â **has become the de-facto standard**Â for your cloud-native apps to (auto-)Â [scale-out](https://stackoverflow.com/a/11715598/5246670)Â and deploy your open-source zoo fast, cloud-provider-independent. No lock-in here. Kubernetes is theÂ **move from infrastructure as code**Â towardsÂ **infrastructure as data**, specifically asÂ [YAML](term/yaml.md). With Kubernetes, developers can quickly write applications that run across multiple operating environments. Costs can be reduced by scaling down.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Lambda-Architecture":{"title":"What is a Lambda Architecture","content":"Lambda architectureÂ is aÂ data-processingÂ architecture designed to handle massive quantities of data by taking advantage of bothÂ batchÂ andÂ stream-processingÂ methods. This approach to architecture attempts to balanceÂ latency,Â throughput, andÂ fault tolerance using batch processing to provide comprehensive and accurate views of batch data, while simultaneously using real-time stream processing to provide views of online data. The two view outputs may be joined before the presentation. The rise of lambda architecture is correlated with the growth ofÂ big data, real-time analytics, and the drive to mitigate the latencies ofÂ [MapReduce](term/mapreduce.md).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/MapReduce":{"title":"What is MapReduce","content":"MapReduce is a programming paradigm that enables massive scalability across hundreds or thousands of servers in a Hadoop cluster. As the processing component, MapReduce is the heart of [Apache Hadoop](term/apache%20hadoop.md). The term \"MapReduce\" refers to two separate and distinct tasks that Apache Hadoop programs perform.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Metrics-Layer":{"title":"What is a Metrics Layer","content":"A Metrics Layer also called Headless BI or sometimes Semantic Layer includes a specification of metrics such as measures and dimensions. Additionally, it can contain model parsing from files (mostlyÂ [YAML](term/yaml.md) and APIs to create and execute metric logic; some include a cache layer. A Metrics Layers encourages us to enforce theÂ [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)Â (Do not repeat yourself) principle by defining it once and population it to any BI tools used or integrated into internal applications or processes\n\nâ€","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Modern-Data-Stack":{"title":"What is Modern Data Stack","content":"The Modern Data Stack (MDS) is a heap of open-source tools to achieve end-to-end analytics from ingestion to transformation to ML over to a columnar data warehouse or lake solution with an analytics BI dashboard backend. This stack is extendable in any way needed, such as data quality, [Data Catalog](term/data%20catalog.md), etc.\n\nThe goal of an MDS is to get data insight with the best suitable tools for each part. It's noteworthy that it's a relatively new term and not yet 100% agreed on.\n","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/ORC":{"title":"What is ORC","content":"TheÂ **Optimized Row Columnar**Â (ORC)Â [Data Lake File Format](term/data%20lake%20file%20format.md)Â provides a highly efficient way to store Hive data. It was designed to overcome the limitations of the other Hive file formats. Using ORC files improves performance when Hive is reading, writing, and processing data.\n\nRead more about how to build a Data Lake on top of it on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).\n","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Schema-Evolution":{"title":"What is Schema Evolution","content":"Automatic Schema Evolution is a crucial feature inÂ [Data Lake Table Format](term/data%20lake%20table%20format.md)s as changing formats is still a pain in today's data engineer work. Schema Evolution means adding new columns without breaking anything or even enlarging some types. You can even rename or reorder columns, although that might break backward compatibilities. Still, we can change one table, and the table format takes care of switching it on all distributed files. Best of all does not require e rewrite of your table and underlying files.\n\nSee also [ACID Transactions](term/acid%20transactions.md).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Slowly-Changing-Dimension":{"title":"What is Slowly Changing Dimension","content":"A Slowly Changing Dimension (SCD) isÂ **a dimension that stores and manages both current and historical data over time in aÂ [Data Warehouse](term/data%20warehouse.md)**. It is considered and implemented as one of the most critical ETL tasks in tracking the history of dimension records.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Soft-Deletes":{"title":"What is Soft Deletes","content":"In order to propagate records that have been deleted when usingÂ [incremental synchronization](term/incremental%20synchronization.md)Â modes, records in a database may include a field that indicates that a record should be treated as if it has been removed. This is necessary because incremental synchronization does not replicate documents that are fully deleted from a source system.  \n  \nFor example, a boolean flag such as \"is_deleted\" could be used to indicate that a record should be treated as if it has been deleted. All queries would need to be written so as to exclude records/documents where \"is_deleted\" is set, and periodically executed background jobs can be used to remove all documents where \"is_deleted\"Â is set.\n\nâ€\n","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Storage-Layer":{"title":"What is a Storage Layer","content":"A storage layer or object storage are services from the three big cloud providers, AWS S3, Azure Blob Storage, and Google Cloud Storage. The web user interface is easy to use.Â **Its features are very basic, where, in fact, these object stores store distributed files exceptionally well.**Â They are also highly configurable, with solid security and reliability built-in.\n\nYou can build on with  [Data Lake File Format](term/data%20lake%20file%20format.md) or [Data Lake Table Format](term/data%20lake%20table%20format.md). Read more on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/Time-Travel":{"title":"What is Time Travel","content":"With time travel, theÂ [Data Lake Table Format](term/data%20lake%20table%20format.md)Â versions the big data you store in yourÂ [Data Lake](term/data%20lake.md). You can access any historical version of that data, simplifying data management with easy-to-audit, rollback data in case of accidental bad writes or deletes, and reproduce experiments and reports. Time travel enables reproducible queries as you can query two different versions simultaneously.\n\nRead more about how to build a Data Lake on top of it on ourÂ [Data Lake and Lakehouse Guide](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi).","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null},"/term/YAML":{"title":"What is YAML","content":"YAML is a data serialization language often used to write configuration files. Depending on whom you ask, YAML stands for yet another markup language, or YAML isnâ€™t markup language (a recursive acronym), which emphasizes that YAML is for data, not documents.","lastmodified":"2022-09-01T12:06:05.163493747Z","tags":null}}